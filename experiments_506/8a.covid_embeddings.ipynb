{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1058,
     "status": "ok",
     "timestamp": 1747084575752,
     "user": {
      "displayName": "Rachel Gao",
      "userId": "08712295941136164624"
     },
     "user_tz": 420
    },
    "id": "OaQV-abl3T0k",
    "outputId": "d3ef6169-a05d-449f-c193-4aab489e6f3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 19286,
     "status": "ok",
     "timestamp": 1747084595037,
     "user": {
      "displayName": "Rachel Gao",
      "userId": "08712295941136164624"
     },
     "user_tz": 420
    },
    "id": "ckBvfuloZACW"
   },
   "outputs": [],
   "source": [
    "%pip install nupunkt -q\n",
    "\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nupunkt import sent_tokenize\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13980,
     "status": "ok",
     "timestamp": 1747084609008,
     "user": {
      "displayName": "Rachel Gao",
      "userId": "08712295941136164624"
     },
     "user_tz": 420
    },
    "id": "SEK5OBbfcs15",
    "outputId": "22fe0d2c-3b7b-40ac-a3c5-1f5fcac0849a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"answerdotai/ModernBERT-base\"\n",
    "\n",
    "TOKENIZER = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "MODEL = AutoModel.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206,
     "output_embedded_package_id": "1h08kr0FCkFH0IiGV3tjNzyWqXeTRkDZp"
    },
    "executionInfo": {
     "elapsed": 6208,
     "status": "ok",
     "timestamp": 1747084615227,
     "user": {
      "displayName": "Rachel Gao",
      "userId": "08712295941136164624"
     },
     "user_tz": 420
    },
    "id": "aHsaAJvP3R1V",
    "outputId": "5280e0a5-0565-4eb9-a47e-216530c3262d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_json('/content/drive/MyDrive/metadata/COVID.json')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1747084615259,
     "user": {
      "displayName": "Rachel Gao",
      "userId": "08712295941136164624"
     },
     "user_tz": 420
    },
    "id": "Dqu0mTuf9ovK",
    "outputId": "00a45308-9ccb-4a11-bdba-9b9172b3b55a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5763182,
     "status": "ok",
     "timestamp": 1747090378442,
     "user": {
      "displayName": "Rachel Gao",
      "userId": "08712295941136164624"
     },
     "user_tz": 420
    },
    "id": "YGJgZfMpgrPJ",
    "outputId": "c6a78654-55cc-466d-b0b0-f1d6c18789d9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [1:36:03<00:00, 24.01s/it]\n"
     ]
    }
   ],
   "source": [
    "MODEL.to('cuda')\n",
    "\n",
    "BATCH_SIZE = 12\n",
    "\n",
    "for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    case_id = row[\"case_id\"]\n",
    "    #print(f\"Processing: \", index)\n",
    "\n",
    "    chunks = ast.literal_eval(row[\"chunks\"])\n",
    "\n",
    "    all_embeddings = []\n",
    "\n",
    "    for i in range(0, len(chunks), BATCH_SIZE):\n",
    "        batch = chunks[i:i + BATCH_SIZE]\n",
    "\n",
    "        # Tokenize and move inputs to GPU\n",
    "        inputs = TOKENIZER(batch, max_length=8192, padding=True, truncation=True, return_tensors='pt')\n",
    "        inputs = {k: v.to('cuda') for k, v in inputs.items()}\n",
    "\n",
    "        # Run model on batch\n",
    "        with torch.no_grad():\n",
    "            outputs = MODEL(**inputs)\n",
    "            last_hidden_state = outputs.last_hidden_state  # shape: [batch, seq_len, hidden_dim]\n",
    "            #print(\"lhs: \", last_hidden_state.shape)\n",
    "\n",
    "            mean_embeddings = last_hidden_state.mean(dim=1)  # shape: [batch, hidden_dim]\n",
    "            all_embeddings.append(mean_embeddings.cpu())\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Combine all embeddings: [n_chunks, hidden_dim]\n",
    "    all_embeddings_tensor = torch.cat(all_embeddings, dim=0)\n",
    "    final_embedding = all_embeddings_tensor.mean(dim=0).numpy()\n",
    "    #print(\"embed: \", final_embedding.shape)\n",
    "\n",
    "    df.at[index, 'mean_embedding'] = final_embedding.astype(object)\n",
    "\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 1092,
     "status": "ok",
     "timestamp": 1747090379533,
     "user": {
      "displayName": "Rachel Gao",
      "userId": "08712295941136164624"
     },
     "user_tz": 420
    },
    "id": "3sBYm3sR3b8L"
   },
   "outputs": [],
   "source": [
    "#df[\"max_embedding\"] = df[\"max_embedding\"].apply(lambda x: x.tolist() if isinstance(x, np.ndarray) else x)\n",
    "df[\"mean_embedding\"] = df[\"mean_embedding\"].apply(lambda x: x.tolist() if isinstance(x, np.ndarray) else x)\n",
    "\n",
    "df.to_json('/content/drive/MyDrive/metadata/embeddings/COVID_embeddings.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293,
     "output_embedded_package_id": "1kGyEP8LM2SwwcQg6k7K8RwZXBDSZJD9-"
    },
    "executionInfo": {
     "elapsed": 1426,
     "status": "ok",
     "timestamp": 1747090380958,
     "user": {
      "displayName": "Rachel Gao",
      "userId": "08712295941136164624"
     },
     "user_tz": 420
    },
    "id": "ZQcgupWJWNzl",
    "outputId": "9f9809ff-917f-4473-9932-be7d81bca201"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN8+fr/YB7OGv0DKZsq0hHO",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
