{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMqhVtu8MinmPwcccmPZLWG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"f5ee0a557f7f4bdd8fe297ba3b80a3c6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b47edbf3731b41c6b7f580f12ee47191","IPY_MODEL_ca0b52d18512466a9c5fd153bd47ebc8","IPY_MODEL_ff2acae80c26473680ac8f42f112edbb"],"layout":"IPY_MODEL_025e0c74ba37427aa56bc7a082d2c46a"}},"b47edbf3731b41c6b7f580f12ee47191":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4007c0e31414eeea21b57af4f17e8b7","placeholder":"​","style":"IPY_MODEL_5b814f40d3a34352a6cc9951d0d5d8a0","value":"model.safetensors: 100%"}},"ca0b52d18512466a9c5fd153bd47ebc8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ddc78f8882d4ef796766bc6319aefdf","max":598559756,"min":0,"orientation":"horizontal","style":"IPY_MODEL_58337c4900f242b39d9062e5c843c581","value":598559756}},"ff2acae80c26473680ac8f42f112edbb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e52227505a184f60aeae61f7aab21129","placeholder":"​","style":"IPY_MODEL_c813ab231e024db2bad69679e7ee187e","value":" 599M/599M [00:20&lt;00:00, 37.6MB/s]"}},"025e0c74ba37427aa56bc7a082d2c46a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4007c0e31414eeea21b57af4f17e8b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b814f40d3a34352a6cc9951d0d5d8a0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5ddc78f8882d4ef796766bc6319aefdf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58337c4900f242b39d9062e5c843c581":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e52227505a184f60aeae61f7aab21129":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c813ab231e024db2bad69679e7ee187e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":[],"metadata":{"id":"hnbIc2-Qzmkf","executionInfo":{"status":"ok","timestamp":1745525950760,"user_tz":420,"elapsed":7,"user":{"displayName":"Rachel Gao","userId":"08712295941136164624"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xwiEfT8fzmEN","executionInfo":{"status":"ok","timestamp":1745525951404,"user_tz":420,"elapsed":614,"user":{"displayName":"Rachel Gao","userId":"08712295941136164624"}},"outputId":"e49eb65d-b622-4754-bf04-93e6e1dcb53f"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","import torch\n","from transformers import AutoTokenizer, ModernBertForSequenceClassification, TrainingArguments, Trainer\n","from torch.utils.data import DataLoader, Dataset\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from sklearn.metrics import classification_report, f1_score, accuracy_score\n","\n","!pip install tqdm -q\n","from tqdm import tqdm"],"metadata":{"id":"DxYuzpaMzm5s","executionInfo":{"status":"ok","timestamp":1745525983288,"user_tz":420,"elapsed":31883,"user":{"displayName":"Rachel Gao","userId":"08712295941136164624"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["file_path = '/content/drive/My Drive/metadata/4a.train.json'\n","df = pd.read_json(file_path)\n","len(df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VgW4xJaC77xV","executionInfo":{"status":"ok","timestamp":1745525987868,"user_tz":420,"elapsed":4582,"user":{"displayName":"Rachel Gao","userId":"08712295941136164624"}},"outputId":"f1b01fa0-547c-4b6a-ea81-e95c3be27e22"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4578"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["mlb = MultiLabelBinarizer()\n","df[\"binarized_labels\"] = mlb.fit_transform(df[\"filtered_issues\"]).tolist()\n","\n","train_texts, val_texts, train_labels, val_labels = train_test_split(\n","    df[\"docket_entries\"], df[\"binarized_labels\"], test_size=0.2, random_state=42\n",")"],"metadata":{"id":"5Oj9e7Vh7-6L","executionInfo":{"status":"ok","timestamp":1745525987909,"user_tz":420,"elapsed":47,"user":{"displayName":"Rachel Gao","userId":"08712295941136164624"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Load tokenizer and model\n","model_name = \"answerdotai/ModernBERT-base\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","# Load model with correct number of labels\n","model = ModernBertForSequenceClassification.from_pretrained(\n","    model_name,\n","    num_labels=len(mlb.classes_),\n","    problem_type=\"multi_label_classification\"\n",")\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"DEVICE: \", device)\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xiFsqHS8z1Gx","executionInfo":{"status":"ok","timestamp":1745525992590,"user_tz":420,"elapsed":4680,"user":{"displayName":"Rachel Gao","userId":"08712295941136164624"}},"outputId":"634cc1d8-bb7f-4494-bdae-6203102fe058"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["DEVICE:  cuda\n"]},{"output_type":"execute_result","data":{"text/plain":["ModernBertForSequenceClassification(\n","  (model): ModernBertModel(\n","    (embeddings): ModernBertEmbeddings(\n","      (tok_embeddings): Embedding(50368, 768, padding_idx=50283)\n","      (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (drop): Dropout(p=0.0, inplace=False)\n","    )\n","    (layers): ModuleList(\n","      (0): ModernBertEncoderLayer(\n","        (attn_norm): Identity()\n","        (attn): ModernBertAttention(\n","          (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n","          (rotary_emb): ModernBertRotaryEmbedding()\n","          (Wo): Linear(in_features=768, out_features=768, bias=False)\n","          (out_drop): Identity()\n","        )\n","        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): ModernBertMLP(\n","          (Wi): Linear(in_features=768, out_features=2304, bias=False)\n","          (act): GELUActivation()\n","          (drop): Dropout(p=0.0, inplace=False)\n","          (Wo): Linear(in_features=1152, out_features=768, bias=False)\n","        )\n","      )\n","      (1-21): 21 x ModernBertEncoderLayer(\n","        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): ModernBertAttention(\n","          (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n","          (rotary_emb): ModernBertRotaryEmbedding()\n","          (Wo): Linear(in_features=768, out_features=768, bias=False)\n","          (out_drop): Identity()\n","        )\n","        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): ModernBertMLP(\n","          (Wi): Linear(in_features=768, out_features=2304, bias=False)\n","          (act): GELUActivation()\n","          (drop): Dropout(p=0.0, inplace=False)\n","          (Wo): Linear(in_features=1152, out_features=768, bias=False)\n","        )\n","      )\n","    )\n","    (final_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (head): ModernBertPredictionHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=False)\n","    (act): GELUActivation()\n","    (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (drop): Dropout(p=0.0, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=41, bias=True)\n",")"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["def tokenize_and_encode(texts, labels):\n","    tokenized = tokenizer(texts, padding=\"max_length\", truncation=True, max_length=512)\n","    tokenized[\"labels\"] = labels\n","    return tokenized\n","\n","train_encodings = tokenize_and_encode(train_texts.tolist(), train_labels.tolist())\n","val_encodings = tokenize_and_encode(val_texts.tolist(), val_labels.tolist())"],"metadata":{"id":"C7MN5LnP7-8n","executionInfo":{"status":"ok","timestamp":1745526150702,"user_tz":420,"elapsed":158114,"user":{"displayName":"Rachel Gao","userId":"08712295941136164624"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["class MultiLabelDataset(Dataset):\n","    def __init__(self, encodings):\n","        self.encodings = encodings\n","\n","    def __len__(self):\n","        return len(self.encodings[\"input_ids\"])\n","\n","    def __getitem__(self, idx):\n","        item = {\n","            key: torch.tensor(val[idx]) for key, val in self.encodings.items() if key != \"labels\"\n","        }\n","        item[\"labels\"] = torch.tensor(self.encodings[\"labels\"][idx], dtype=torch.float)\n","        return item\n","\n","train_dataset = MultiLabelDataset(train_encodings)\n","val_dataset = MultiLabelDataset(val_encodings)"],"metadata":{"id":"fdBS1FsB8nRb","executionInfo":{"status":"ok","timestamp":1745526168170,"user_tz":420,"elapsed":3,"user":{"displayName":"Rachel Gao","userId":"08712295941136164624"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    probs = torch.sigmoid(torch.tensor(logits)).numpy()\n","    preds = (probs > 0.5).astype(int)\n","\n","    return {\n","        \"f1_micro\": f1_score(labels, preds, average=\"micro\"),\n","        \"f1_macro\": f1_score(labels, preds, average=\"macro\"),\n","        \"accuracy\": accuracy_score(labels, preds),\n","    }"],"metadata":{"id":"cs9aRlHY89su","executionInfo":{"status":"ok","timestamp":1745526169824,"user_tz":420,"elapsed":3,"user":{"displayName":"Rachel Gao","userId":"08712295941136164624"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["training_args = TrainingArguments(\n","    output_dir=\"/content/drive/My Drive/metadata/model/\",\n","    num_train_epochs=1,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    learning_rate=2e-5,\n","    warmup_ratio=0.1,\n","    fp16=True,\n","    bf16=False,\n","    eval_strategy=\"steps\",\n","    eval_steps=100,\n","    save_strategy=\"steps\",\n","    save_steps=100,\n","    save_total_limit=2,\n","    report_to=\"none\"\n",")"],"metadata":{"id":"Yqh-E5GD8_hQ","executionInfo":{"status":"ok","timestamp":1745526171413,"user_tz":420,"elapsed":20,"user":{"displayName":"Rachel Gao","userId":"08712295941136164624"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    compute_metrics=compute_metrics,\n","    tokenizer=tokenizer,\n",")\n","\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":325},"id":"fToVu1uB8_jQ","executionInfo":{"status":"ok","timestamp":1745527220799,"user_tz":420,"elapsed":1047924,"user":{"displayName":"Rachel Gao","userId":"08712295941136164624"}},"outputId":"dc51daa2-20c3-4633-f73a-da7f8056fad5"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-10-21ae03a2d60d>:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='458' max='458' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [458/458 17:19, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>F1 Micro</th>\n","      <th>F1 Macro</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>No log</td>\n","      <td>0.283043</td>\n","      <td>0.280333</td>\n","      <td>0.036676</td>\n","      <td>0.068777</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>No log</td>\n","      <td>0.244953</td>\n","      <td>0.308955</td>\n","      <td>0.047790</td>\n","      <td>0.067686</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>No log</td>\n","      <td>0.237952</td>\n","      <td>0.343496</td>\n","      <td>0.062970</td>\n","      <td>0.025109</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>No log</td>\n","      <td>0.231270</td>\n","      <td>0.318625</td>\n","      <td>0.052961</td>\n","      <td>0.065502</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["W0424 20:23:37.825000 9322 torch/_inductor/utils.py:1137] [1/1] Not enough SMs to use max_autotune_gemm mode\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=458, training_loss=0.2744152285646663, metrics={'train_runtime': 1047.4122, 'train_samples_per_second': 3.496, 'train_steps_per_second': 0.437, 'total_flos': 1248192620783616.0, 'train_loss': 0.2744152285646663, 'epoch': 1.0})"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["trainer.evaluate()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":176},"id":"XvTOYQgr8_le","executionInfo":{"status":"ok","timestamp":1745527237009,"user_tz":420,"elapsed":11919,"user":{"displayName":"Rachel Gao","userId":"08712295941136164624"}},"outputId":"a3bb9bcf-465c-4ea6-def2-3d6bc0cb38de"},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='115' max='115' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [115/115 00:11]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 0.23033729195594788,\n"," 'eval_f1_micro': 0.3398516520566419,\n"," 'eval_f1_macro': 0.06383013327891142,\n"," 'eval_accuracy': 0.05895196506550218,\n"," 'eval_runtime': 11.9056,\n"," 'eval_samples_per_second': 76.938,\n"," 'eval_steps_per_second': 9.659,\n"," 'epoch': 1.0}"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["!huggingface-cli login"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PNFOMANtiD_o","executionInfo":{"status":"ok","timestamp":1745527298076,"user_tz":420,"elapsed":37758,"user":{"displayName":"Rachel Gao","userId":"08712295941136164624"}},"outputId":"0ee40317-16c3-4add-a738-c61534709c16"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n","    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n","    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n","    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n","    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n","\n","    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n","Enter your token (input will not be visible): \n","Add token as git credential? (Y/n) Y\n","Token is valid (permission: fineGrained).\n","The token `FLP` has been saved to /root/.cache/huggingface/stored_tokens\n","\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n","You might have to re-authenticate when pushing to the Hugging Face Hub.\n","Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n","\n","git config --global credential.helper store\n","\n","Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n","Token has not been saved to git credential helper.\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful.\n","The current active token is: `FLP`\n"]}]},{"cell_type":"code","source":["# Save the trained model\n","model.save_pretrained(f\"/content/drive/My Drive/metadata/model/final\")"],"metadata":{"id":"-g_9agJniZ9u","executionInfo":{"status":"ok","timestamp":1745527468832,"user_tz":420,"elapsed":109460,"user":{"displayName":"Rachel Gao","userId":"08712295941136164624"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Push the trained model to hub\n","model.push_to_hub(f\"finetune_try\", private=True, exist_ok=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":118,"referenced_widgets":["f5ee0a557f7f4bdd8fe297ba3b80a3c6","b47edbf3731b41c6b7f580f12ee47191","ca0b52d18512466a9c5fd153bd47ebc8","ff2acae80c26473680ac8f42f112edbb","025e0c74ba37427aa56bc7a082d2c46a","e4007c0e31414eeea21b57af4f17e8b7","5b814f40d3a34352a6cc9951d0d5d8a0","5ddc78f8882d4ef796766bc6319aefdf","58337c4900f242b39d9062e5c843c581","e52227505a184f60aeae61f7aab21129","c813ab231e024db2bad69679e7ee187e"]},"id":"EzfwKCHQiczO","executionInfo":{"status":"ok","timestamp":1745527620076,"user_tz":420,"elapsed":151232,"user":{"displayName":"Rachel Gao","userId":"08712295941136164624"}},"outputId":"80b574c5-6fbe-4f42-823b-7ae4b68d51ab"},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/599M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5ee0a557f7f4bdd8fe297ba3b80a3c6"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["CommitInfo(commit_url='https://huggingface.co/rachelFLP/finetune_try/commit/2e8e829965e8bd725fe9eb65a3ee17425dd80467', commit_message='Upload ModernBertForSequenceClassification', commit_description='', oid='2e8e829965e8bd725fe9eb65a3ee17425dd80467', pr_url=None, repo_url=RepoUrl('https://huggingface.co/rachelFLP/finetune_try', endpoint='https://huggingface.co', repo_type='model', repo_id='rachelFLP/finetune_try'), pr_revision=None, pr_num=None)"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":14}]}]}